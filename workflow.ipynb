{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import modin.pandas as mpd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.ticker as ticker\n",
    "import mplfinance as mpf\n",
    "from multiprocessing import Pool\n",
    "from contextlib import contextmanager\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import clear_output\n",
    "import dill as pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# causis api\n",
    "from causis_api.const import get_version\n",
    "from causis_api.const import login\n",
    "login.username = 'shuai.song'\n",
    "login.password = 'Tsinghua2022'\n",
    "login.version = get_version()\n",
    "from causis_api.data import *\n",
    "from causis_api.tool import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Data Preparation\n",
    "The strategy is executed on identical base positions. In this case, the base positions are components of CSI 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ CST500 components weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weights = pd.read_pickle('./dataset/tmp_position.pkl')\n",
    "\n",
    "Arrange_dates = list(index_weights['df_t0_trade'].loc[index_weights['df_t0_trade']==False].index)\n",
    "Arrange_dates.append(pd.to_datetime('2022-07-08 00:00:00'))\n",
    "\n",
    "stock_weights = index_weights['df_pos'].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_Matrix = index_weights['df_pos'].transpose()\n",
    "\n",
    "for d in Weight_Matrix.columns:\n",
    "    Weight_Matrix[d] = Weight_Matrix[d] / Weight_Matrix[d].sum()\n",
    "\n",
    "Weight_Matrix = Weight_Matrix.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Data of the base positions (daily, min_bars, price & volumes needed) has been prepared and is stored in ./CST500_1min.pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Pos = pd.read_pickle('./dataset/CSI500_1min.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Data Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patching1: 100%|██████████| 774/774 [00:00<00:00, 387628.81it/s]\n",
      "Patching2: 100%|██████████| 774/774 [00:21<00:00, 36.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No New Patch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_patch = False\n",
    "\n",
    "for id in tqdm(Weight_Matrix.columns, desc='Patching1'):\n",
    "    if id not in Base_Pos.keys():\n",
    "        df = get_price(id, '2019-11-29', '2022-07-08', 'minute1')\n",
    "        if df.shape[0]:\n",
    "            df = df.set_index('CLOCK', drop=False)\n",
    "            Base_Pos[id] = df\n",
    "            new_patch = True\n",
    "\n",
    "for symbol in tqdm(Base_Pos.keys(), desc='Patching2'):\n",
    "    if Base_Pos[symbol]['CLOCK'].shape[0]:\n",
    "        if isinstance(Base_Pos[symbol]['CLOCK'][0], float):\n",
    "            Base_Pos[symbol]['CLOCK'] = list(Base_Pos[symbol].index)\n",
    "            new_patch = True\n",
    "\n",
    "if new_patch:\n",
    "    with open('./dataset/CSI500_1min.pkl', 'wb') as f:\n",
    "        pickle.dump(Base_Pos, f)\n",
    "    print(\"New Patch\")\n",
    "else:\n",
    "    print(\"No New Patch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Environment Variables\n",
    "+ Global Settings of Strategy and Backtest Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_S_MA_WIN = 5\n",
    "P_L_MA_WIN = 10\n",
    "\n",
    "V_S_MA_WIN = 5\n",
    "V_L_MA_WIN = 10\n",
    "\n",
    "P_S_EMA_WIN = 12\n",
    "P_L_EMA_WIN = 26\n",
    "\n",
    "DEA_WIN = 9\n",
    "\n",
    "H_MAX_WIN = 10\n",
    "L_MIN_WIN = 10\n",
    "\n",
    "FLUCT_TS = 0.01\n",
    "ATR_WIN = 10\n",
    "\n",
    "TRI_WIN = 3\n",
    "PROFIT_INTERRUPT_MUL = 1.0\n",
    "LOSS_INTERRUPT_MUL = 0.0\n",
    "\n",
    "ACCOUNT = 1e6\n",
    "\n",
    "COLORS = ['darkorange', 'cyan', 'royalblue', 'deeppink', 'indianred', 'limegreen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Function *technical_analysis* calculates all the technical features we need, most important of which are 3 signals and fluctuations.\n",
    "+ Function *tri_forks_filter* aggregates above four features and generates execution signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_forks_filter(_stmp, winsize):\n",
    "    _stmp['rolling'] = list(_stmp.rolling(winsize))\n",
    "    _stmp['execution'] = np.zeros(_stmp.shape[0])\n",
    "    _stmp['pos_signal_count'] = _stmp['rolling'].apply(lambda x: x['signal1'].sum()) + _stmp['rolling'].apply(lambda x: x['signal3'].sum())\n",
    "    _stmp['neg_signal_count'] = _stmp['rolling'].apply(lambda x: x['signal1'].sum()) + _stmp['rolling'].apply(lambda x: x['signal3'].sum())\n",
    "\n",
    "    long_condition = (_stmp['pos_signal_count'] == 2) & (_stmp['Fluct'] > FLUCT_TS)\n",
    "    short_condition = (_stmp['neg_signal_count'] == -2) & (_stmp['Fluct'] > FLUCT_TS)\n",
    "\n",
    "    _stmp['execution'][long_condition] = 1\n",
    "    _stmp['execution'][short_condition] = -1\n",
    "\n",
    "    return _stmp['execution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager \n",
    "def timer(name: str, _log): # ⏱\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    if _log:\n",
    "        print(f\"{ '[' + name + ']' :25} {elapsed: .3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_analysis(stmp, _filter, log = True):\n",
    "    \n",
    "    with timer('BS_price & ATR', log):\n",
    "        ## Base Position Price\n",
    "        stmp['BS_price'] = stmp['CLOSE'].shift(1)\n",
    "\n",
    "        ## ATR\n",
    "        _TR = [np.abs(stmp['HIGH'][0]-stmp['LOW'][0])]\n",
    "        for i in range(1, stmp.shape[0]):\n",
    "            _TR.append(max(np.abs(stmp['HIGH'][i]-stmp['LOW'][i]), np.abs(stmp['HIGH'][i]-stmp['CLOSE'][i-1]), np.abs(stmp['LOW'][i]-stmp['CLOSE'][i-1])))\n",
    "        stmp['TR'] = _TR\n",
    "        stmp['ATR'] = stmp['TR'].rolling(ATR_WIN).mean()\n",
    "\n",
    "    with timer('Price Mean', log):\n",
    "        ## Price Mean\n",
    "        stmp['P_L_MA'] = stmp['CLOSE'].rolling(P_L_MA_WIN).mean()\n",
    "        stmp['P_S_MA'] = stmp['CLOSE'].rolling(P_S_MA_WIN).mean()\n",
    "    \n",
    "    with timer('Volume Mean', log):\n",
    "        ## Volume Mean\n",
    "        stmp['V_L_MA'] = stmp['VOLUME'].rolling(V_L_MA_WIN).mean()\n",
    "        stmp['V_S_MA'] = stmp['VOLUME'].rolling(V_S_MA_WIN).mean()\n",
    "\n",
    "    with timer('MACD', log):\n",
    "        ## MACD\n",
    "        stmp['DIF'] = stmp['CLOSE'].ewm(span=P_S_EMA_WIN, adjust=False).mean() - stmp['CLOSE'].ewm(span=P_L_EMA_WIN, adjust=False).mean()\n",
    "        stmp['DEA'] = stmp['DIF'].ewm(span=DEA_WIN, adjust=False).mean()\n",
    "\n",
    "    with timer('Channel', log):\n",
    "        ## Boundaries \n",
    "        stmp['H_max'] = stmp['HIGH'].rolling(H_MAX_WIN).max()\n",
    "        stmp['L_min'] = stmp['LOW'].rolling(L_MIN_WIN).min()\n",
    "    \n",
    "    with timer('Fluctuation', log):\n",
    "        ## Fluctuation\n",
    "        stmp['Fluct'] = (stmp['H_max'] - stmp['L_min'])/stmp['CLOSE']\n",
    "\n",
    "    with timer('SIGNAL 1: Price Forks', log):\n",
    "        ## SIGNAL 1: Price Forks\n",
    "        stmp['sign1'] = np.sign(stmp['P_S_MA'] - stmp['P_L_MA'])\n",
    "        stmp['signal1'] = 2*stmp['sign1']/(2-np.abs(stmp['sign1']+stmp['sign1'].shift(1)))\n",
    "        stmp['signal1'] = stmp['signal1'].replace([np.inf, -np.inf], np.nan)\n",
    "        stmp['signal1'] = stmp['signal1'].fillna(0)\n",
    "\n",
    "    with timer('SIGNAL 2: Volume Forks', log):\n",
    "        ## SIGNAL 2: Volume Forks\n",
    "        stmp['sign2'] = np.sign(stmp['V_S_MA'] - stmp['V_L_MA'])\n",
    "        stmp['signal2'] = 2*stmp['sign2']/(2-np.abs(stmp['sign2']+stmp['sign2'].shift(1)))\n",
    "        stmp['signal2'] = stmp['signal2'].replace([np.inf, -np.inf], np.nan)\n",
    "        stmp['signal2'] = stmp['signal2'].fillna(0)\n",
    "\n",
    "    with timer('SIGNAL 3: MACD Forks', log):\n",
    "        ## SIGNAL 3: MACD Forks\n",
    "        stmp['sign3'] = np.sign(stmp['DIF'] - stmp['DEA'])\n",
    "        stmp['signal3'] = 2*stmp['sign3']/(2-np.abs(stmp['sign3']+stmp['sign3'].shift(1)))\n",
    "        stmp['signal3'] = stmp['signal3'].replace([np.inf, -np.inf], np.nan)\n",
    "        stmp['signal3'] = stmp['signal3'].fillna(0)\n",
    "\n",
    "    with timer('Execution', log):\n",
    "        # Execution\n",
    "        stmp['execution'] = _filter(stmp, TRI_WIN)\n",
    "\n",
    "    return stmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Time to enter (open positions) has been generated in above features calculation.\n",
    "+ Most operations in *basic_LS* are used to decide when to close positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_LS(_smp, account, _fees = True):\n",
    "    _date = _smp['CLOCK'][0][:10]\n",
    "    V1 = 100*int(((account/_smp['BS_price'][0])*0.1)/100)\n",
    "    \n",
    "    def solid_bar_time(_time):\n",
    "        if (_date + ' 11:30:00' < _time) and (_time < _date + ' 13:00:00'):\n",
    "            _time = str(pd.to_datetime(_time) + datetime.timedelta(hours=1, minutes=30))\n",
    "\n",
    "        if _time == _date + ' 13:00:00':\n",
    "            _time = str(pd.to_datetime(_time) + datetime.timedelta(minutes=1))\n",
    "                    \n",
    "        return _time\n",
    "\n",
    "    pos_trading_points = _smp[:_date+' 14:55:00'].loc[(_smp['execution'] == 1)]['CLOCK'].to_list()\n",
    "    neg_trading_points = _smp[:_date+' 14:55:00'].loc[(_smp['execution'] == -1)]['CLOCK'].to_list()\n",
    "\n",
    "    _smp['Position'] = np.zeros(_smp.shape[0])\n",
    "    _smp['close_reason'] = np.zeros(_smp.shape[0])\n",
    "\n",
    "    ## Gains from positive forks\n",
    "    pos_fork_gains = []\n",
    "    last_close_buy_bar = _smp['CLOCK'][0]\n",
    "    long_num = 0\n",
    "    for t1 in pos_trading_points:\n",
    "        open_buy_bar = solid_bar_time(str(pd.to_datetime(t1) + datetime.timedelta(minutes=1)))\n",
    "        open_buy_price = _smp.loc[open_buy_bar]['OPEN']\n",
    "\n",
    "        # at most 5 short executions\n",
    "        if long_num > 5:\n",
    "            break\n",
    "\n",
    "        # Do not open again within 3 mins\n",
    "        if open_buy_bar < str(pd.to_datetime(last_close_buy_bar) + datetime.timedelta(minutes=3)):\n",
    "            continue\n",
    "\n",
    "        # max holding period: inf min \n",
    "        for i in range (1, 1000): \n",
    "            close_buy_bar = solid_bar_time(str(pd.to_datetime(open_buy_bar) + datetime.timedelta(minutes=i)))\n",
    "            buy_bar_bt = solid_bar_time(str(pd.to_datetime(open_buy_bar) + datetime.timedelta(minutes=i+1)))\n",
    "            last_close_buy_bar = close_buy_bar\n",
    "\n",
    "            if close_buy_bar in pos_trading_points: # No appendant position\n",
    "                del pos_trading_points[pos_trading_points.index(close_buy_bar)]\n",
    "\n",
    "            # latest close time\n",
    "            if close_buy_bar >= _date + ' 14:55:00':\n",
    "                close_buy_bar = _date + ' 14:55:00'\n",
    "                close_buy_price = _smp.loc[_date + ' 14:55:00']['OPEN']\n",
    "                _smp['close_reason'][close_buy_bar] = 1 # close reason 1\n",
    "                break\n",
    "\n",
    "            # Trend Weaken interrupt\n",
    "            if (_smp.loc[close_buy_bar]['signal3'] == -1.0):\n",
    "                close_buy_bar = buy_bar_bt\n",
    "                close_buy_price = _smp.loc[buy_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_buy_bar] = 2 # close reason 2\n",
    "                break\n",
    "\n",
    "            if _smp.loc[close_buy_bar]['Fluct'] <= FLUCT_TS:\n",
    "                close_buy_bar = buy_bar_bt\n",
    "                close_buy_price = _smp.loc[buy_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_buy_bar] = 3 # close reason 3\n",
    "                break\n",
    "\n",
    "            # # Volume decrease interrupt\n",
    "            # if _smp.loc[close_buy_bar]['signal2'] == -1.0:\n",
    "            #     close_buy_bar = buy_bar_bt\n",
    "            #     close_buy_price = _smp.loc[buy_bar_bt]['OPEN']\n",
    "            #     _smp['close_reason'][close_buy_bar] = 4 # close reason 4\n",
    "            #     break\n",
    "\n",
    "            # profit interrupt \n",
    "            if _smp.loc[close_buy_bar]['CLOSE'] >= _smp.loc[close_buy_bar]['H_max'] + PROFIT_INTERRUPT_MUL * _smp.loc[close_buy_bar]['ATR']:\n",
    "                close_buy_bar = buy_bar_bt\n",
    "                close_buy_price = _smp.loc[buy_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_buy_bar] = 4 # close reason 4\n",
    "                break\n",
    "\n",
    "            # loss interrupt \n",
    "            if _smp.loc[close_buy_bar]['CLOSE'] <= _smp.loc[close_buy_bar]['P_L_MA'] - LOSS_INTERRUPT_MUL * _smp.loc[close_buy_bar]['ATR']:\n",
    "                close_buy_bar = buy_bar_bt\n",
    "                close_buy_price = _smp.loc[buy_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_buy_bar] = 5 # close reason 5\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: No interrupt -- {_smp['SYMBOL'][0]-{_date}}\")\n",
    "            close_buy_price = _smp.loc[close_buy_bar]['OPEN']\n",
    "\n",
    "        _smp['Position'][open_buy_bar:close_buy_bar] = 1\n",
    "        long_num += 1\n",
    "\n",
    "        # profits\n",
    "        if _fees:\n",
    "            profit_pos = (close_buy_price - open_buy_price) * V1 - (close_buy_price + open_buy_price) * V1 * 2e-4\n",
    "        else:\n",
    "            profit_pos = (close_buy_price - open_buy_price) * V1 \n",
    "\n",
    "        pos_fork_gains.append(round(profit_pos, 4))\n",
    "\n",
    "    ## Gains from negative forks\n",
    "    neg_fork_gains = []\n",
    "    last_close_sell_bar = _smp['CLOCK'][0]\n",
    "    short_num = 0\n",
    "    for t2 in neg_trading_points:\n",
    "        open_sell_bar = solid_bar_time(str(pd.to_datetime(t2) + datetime.timedelta(minutes=1)))\n",
    "        open_sell_price = _smp.loc[open_sell_bar]['OPEN']\n",
    "\n",
    "        # at most 5 short executions\n",
    "        if short_num > 5: \n",
    "            break\n",
    "\n",
    "        # Do not open again within 3 mins\n",
    "        if open_sell_bar < str(pd.to_datetime(last_close_sell_bar) + datetime.timedelta(minutes=3)):\n",
    "            continue\n",
    "\n",
    "        # max holding period: inf min\n",
    "        for i in range (1, 1000):\n",
    "            close_sell_bar = solid_bar_time(str(pd.to_datetime(open_sell_bar) + datetime.timedelta(minutes=i)))\n",
    "            sell_bar_bt = solid_bar_time(str(pd.to_datetime(open_sell_bar) + datetime.timedelta(minutes=i+1)))\n",
    "            last_close_sell_bar = close_sell_bar\n",
    "\n",
    "            if close_sell_bar in neg_trading_points:\n",
    "                del neg_trading_points[neg_trading_points.index(close_sell_bar)]\n",
    "\n",
    "            # latest close time\n",
    "            if close_sell_bar >= _date + ' 14:55:00':\n",
    "                close_sell_bar = _date + ' 14:55:00'\n",
    "                close_sell_price = _smp.loc[_date + ' 14:55:00']['OPEN']\n",
    "                _smp['close_reason'][close_sell_bar] = 1 # close reason 1\n",
    "                break\n",
    "\n",
    "            # Trend Weaken interrupt\n",
    "            if (_smp.loc[close_sell_bar]['signal3'] == 1.0): \n",
    "                close_sell_bar = sell_bar_bt\n",
    "                close_sell_price = _smp.loc[sell_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_sell_bar] = 2 # close reason 2\n",
    "                break\n",
    "\n",
    "            if _smp.loc[close_sell_bar]['Fluct'] <= FLUCT_TS:\n",
    "                close_sell_bar = sell_bar_bt\n",
    "                close_sell_price = _smp.loc[sell_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_sell_bar] = 3 # close reason 3\n",
    "                break\n",
    "\n",
    "            # # Volume decrease interrupt\n",
    "            # if _smp.loc[close_sell_bar]['signal2'] == -1.0:\n",
    "            #     close_sell_bar = sell_bar_bt\n",
    "            #     close_sell_price = _smp.loc[sell_bar_bt]['OPEN']\n",
    "            #     _smp['close_reason'][close_sell_bar] = 4 # close reason 4\n",
    "            #     break\n",
    "\n",
    "            # profit interrupt \n",
    "            if _smp.loc[close_sell_bar]['CLOSE'] <= _smp.loc[close_sell_bar]['L_min'] - PROFIT_INTERRUPT_MUL * _smp.loc[close_sell_bar]['ATR']:\n",
    "                close_sell_bar = sell_bar_bt\n",
    "                close_sell_price = _smp.loc[sell_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_sell_bar] = 4 # close reason 4\n",
    "                break\n",
    "\n",
    "            # loss interrupt \n",
    "            if _smp.loc[close_sell_bar]['CLOSE'] >= _smp.loc[close_sell_bar]['P_L_MA'] + LOSS_INTERRUPT_MUL * _smp.loc[close_sell_bar]['ATR']:\n",
    "                close_sell_bar = sell_bar_bt\n",
    "                close_sell_price = _smp.loc[sell_bar_bt]['OPEN']\n",
    "                _smp['close_reason'][close_sell_bar] = 5 # close reason 5\n",
    "                break\n",
    "            \n",
    "        else:\n",
    "            close_sell_price = _smp.loc[close_sell_bar]['OPEN']\n",
    "\n",
    "        _smp['Position'][open_sell_bar:close_sell_bar] = -1\n",
    "        short_num += 1\n",
    "\n",
    "        # profits\n",
    "        if _fees:\n",
    "            profit_neg = (open_sell_price - close_sell_price) * V1 - (close_sell_price + open_sell_price) * V1 * 2e-4\n",
    "        else:\n",
    "            profit_neg = (open_sell_price - close_sell_price) * V1 \n",
    "\n",
    "        neg_fork_gains.append(round(profit_neg, 4))\n",
    "\n",
    "    return [_date, pd.Series(pos_fork_gains), pd.Series(neg_fork_gains)], _smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BackTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_stock_simulation(stmp, logger=False):\n",
    "    stock_id = stmp['SYMBOL'][0]\n",
    "    stmp = stmp.set_index('CLOCK', drop=False)\n",
    "\n",
    "    Start_date = max('2019-11-29 00:00:00', stmp['CLOCK'][0])\n",
    "    End_date = min('2022-07-01 15:00:00', stmp['CLOCK'][-1])\n",
    "\n",
    "    stmp = stmp.loc[(Start_date <= stmp['CLOCK']) & (stmp['CLOCK'] <= End_date)]\n",
    "    stmp = stmp[~stmp.index.duplicated()]\n",
    "\n",
    "    if logger: print('Calculating Technical Features...')\n",
    "    ftmp = technical_analysis(stmp, tri_forks_filter, log=logger)\n",
    "    if logger: print('Done')\n",
    "\n",
    "    ftmp = ftmp.loc[str(pd.to_datetime(Start_date)+datetime.timedelta(days=1))<= stmp['CLOCK']]\n",
    "\n",
    "    VTD = list(ftmp['CLOCK'].apply(lambda x: x[:10]).drop_duplicates())\n",
    "\n",
    "    trading_log = pd.DataFrame(columns=['DATE', 'pos_fork_gains', 'neg_fork_gains'])\n",
    "\n",
    "    if logger:\n",
    "        for d in tqdm(VTD[:], desc='Basic_LS'):\n",
    "            tmp_smp = ftmp.loc[(d+' 00:00:00' < ftmp['CLOCK']) & (ftmp['CLOCK'] < d+' 15:01:00')]\n",
    "            entry, tmp_smp = basic_LS(tmp_smp, 1e8, _fees=True)\n",
    "            trading_log.loc[trading_log.shape[0]] = entry\n",
    "    else:\n",
    "        for d in VTD[:]:\n",
    "            tmp_smp = ftmp.loc[(d+' 00:00:00' < ftmp['CLOCK']) & (ftmp['CLOCK'] < d+' 15:01:00')]\n",
    "            entry, tmp_smp = basic_LS(tmp_smp, 1e8, _fees=True)\n",
    "            trading_log.loc[trading_log.shape[0]] = entry\n",
    "\n",
    "    trading_log = trading_log.set_index('DATE', drop=False)\n",
    "    trading_log['pos_fork_gains_sum'] = trading_log['pos_fork_gains'].apply(lambda x: x.sum())\n",
    "    trading_log['neg_fork_gains_sum'] = trading_log['neg_fork_gains'].apply(lambda x: x.sum())\n",
    "    trading_log['total_gains_sum'] = trading_log['pos_fork_gains_sum'] + trading_log['neg_fork_gains_sum']\n",
    "    trading_log = trading_log.reindex(Weight_Matrix.index).fillna(0)\n",
    "    \n",
    "    if logger: clear_output()\n",
    "    \n",
    "    return (stock_id, [list(trading_log['pos_fork_gains_sum']), list(trading_log['neg_fork_gains_sum']), list(trading_log['total_gains_sum'])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "res = []\n",
    "## Parallel BackTest\n",
    "tasks = []\n",
    "for i in range(len(Weight_Matrix.columns)//BATCH_SIZE + 1):\n",
    "    with timer(f'Batch {i}: {BATCH_SIZE*i:3} -- {min(len(Weight_Matrix.columns), BATCH_SIZE*(i+1))-1:3}'):\n",
    "        for col in Weight_Matrix.columns[BATCH_SIZE*i:min(len(Weight_Matrix.columns), BATCH_SIZE*(i+1))]:\n",
    "            stmp_ = Base_Pos[col]\n",
    "            tasks.append(delayed(one_stock_simulation)(stmp_))\n",
    "\n",
    "        multi_work = Parallel(n_jobs=-1)\n",
    "        res += multi_work(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check SYMBOL Order\n",
    "Rank_Order = True\n",
    "for a, b in zip(res, Weight_Matrix.columns):\n",
    "    if a[0] != b:\n",
    "        print(f'{a[0]} != {b}') \n",
    "        Rank_Order = False\n",
    "        break\n",
    "else:\n",
    "    print('All Ranks Correct')\n",
    "\n",
    "Pos_Fork_Gains = pd.DataFrame()\n",
    "Pos_Fork_Gains = Pos_Fork_Gains.reindex(Weight_Matrix.index)\n",
    "\n",
    "Neg_Fork_Gains = pd.DataFrame()\n",
    "Neg_Fork_Gains = Neg_Fork_Gains.reindex(Weight_Matrix.index)\n",
    "\n",
    "Total_Gains = pd.DataFrame()\n",
    "Total_Gains = Total_Gains.reindex(Weight_Matrix.index)\n",
    "\n",
    "if Rank_Order:\n",
    "    ## Allocate Results\n",
    "    for item in res:\n",
    "        Pos_Fork_Gains[item[0]] = item[1][0]\n",
    "        Neg_Fork_Gains[item[0]] = item[1][1]\n",
    "        Total_Gains[item[0]] = item[1][2]\n",
    "\n",
    "    Pos_Fork_Gains_BS = pd.DataFrame(Pos_Fork_Gains.values * Weight_Matrix.values)\n",
    "    Neg_Fork_Gains_BS = pd.DataFrame(Neg_Fork_Gains.values * Weight_Matrix.values)\n",
    "    Total_Gains_BS = pd.DataFrame(Total_Gains.values * Weight_Matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pnl_Cal(_trading_log):\n",
    "    _trading_log['pos_fork_gains_sum'] = _trading_log['pos_fork_gains'].apply(lambda x: x.sum())\n",
    "    _trading_log['neg_fork_gains_sum'] = _trading_log['neg_fork_gains'].apply(lambda x: x.sum())\n",
    "    _trading_log['fork_gains_sum'] = (_trading_log['pos_fork_gains_sum'] + _trading_log['neg_fork_gains_sum'])\n",
    "\n",
    "    _pos_fork_pnl = 1 + _trading_log['pos_fork_gains_sum'].cumsum()/ACCOUNT\n",
    "    _neg_fork_pnl = 1 + _trading_log['neg_fork_gains_sum'].cumsum()/ACCOUNT\n",
    "    _fork_pnl = 1 + _trading_log['fork_gains_sum'].cumsum()/ACCOUNT\n",
    "\n",
    "    return _pos_fork_pnl, _neg_fork_pnl, _fork_pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fork_pnl, neg_fork_pnl, fork_pnl = Pnl_Cal(trading_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "pos_fork_pnl.plot(color='skyblue')\n",
    "neg_fork_pnl.plot(color='orange')\n",
    "fork_pnl.plot(color='green')\n",
    "\n",
    "plt.legend()\n",
    "# plt.title('Tipless Filter, Having Fees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Win Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fork_winrate = []\n",
    "neg_fork_winrate = []\n",
    "for i in range(trading_log.shape[0]):\n",
    "    if trading_log['pos_fork_gains'][i].shape[0]:\n",
    "        _slice = trading_log['pos_fork_gains'][i]\n",
    "        pos_fork_winrate.append(len(_slice.loc[_slice>0])/len(_slice))\n",
    "        \n",
    "    if trading_log['neg_fork_gains'][i].shape[0]:\n",
    "        _slice = trading_log['neg_fork_gains'][i]\n",
    "        neg_fork_winrate.append(len(_slice.loc[_slice>0])/len(_slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), dpi=100)\n",
    "pd.Series(pos_fork_winrate).hist(ax=axes[0], color='gold')\n",
    "axes[0].set_title('Pos Fork Win Rate')\n",
    "pd.Series(neg_fork_winrate).hist(ax=axes[1], color='skyblue')\n",
    "axes[1].set_title('Neg Fork Win Rate')\n",
    "plt.suptitle('Having Filter, Having Fees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profitable_analysis(_pnl):\n",
    "    Annual_r = (_pnl.diff()/_pnl.shift(1)).mean()*252\n",
    "    Std = (_pnl.diff()/_pnl.shift(1)).std()*np.sqrt(252)\n",
    "    Sharpe = Annual_r / Std\n",
    "    MaxDrawdown = (1 - _pnl/pd.Series(list(_pnl.rolling(len(_pnl)))).apply(lambda x: x.max())).max()\n",
    "    Calmar = Annual_r / MaxDrawdown\n",
    "    return Annual_r, Std, Sharpe, MaxDrawdown, Calmar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_analysis(fork_pnl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Plot basic and calculated features of one single trading day.\n",
    "+ Subplot 0: basic information including *Candle bars* and *Positions* (containing reasons why positions are closed)\n",
    "+ Subplot 1: features related to signal 1 including *P_S_MA*, *P_L_MA*, *CLOSE*, and *Signal1*\n",
    "+ Subplot 2: features related to signal 2 including *Volume*, *V_L_MA*, *V_S_MA* and *Signal2*\n",
    "+ Subplot 3: features related to signal 3 including *DIF*, *DEA*, *Close* and *Signal3*\n",
    "+ Subplot 4: features related to Fluctuations including *H_max*, *L_min*, *Fluct* and *FLUCT_TS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all2(smp):\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(20, 15), dpi=200)\n",
    "\n",
    "    ## SUBPLOT 0: Candle bars & Position\n",
    "    axes[0].set_title('Candle bars & Position')\n",
    "    axes[0].grid(False)\n",
    "    axes[0].yaxis.set_ticks_position('left')\n",
    "\n",
    "    sdf = pd.DataFrame()\n",
    "    sdf['CLOCK'] = smp['CLOCK'].apply(lambda x: pd.to_datetime(x))\n",
    "    sdf = sdf.set_index('CLOCK')\n",
    "    sdf['Open'] = smp['OPEN']\n",
    "    sdf['Close'] = smp['CLOSE']\n",
    "    sdf['High'] = smp['HIGH']\n",
    "    sdf['Low'] = smp['LOW']\n",
    "    sdf['Volume'] = smp['VOLUME']\n",
    "\n",
    "    mc = mpf.make_marketcolors(up='red', down='green', edge='black')\n",
    "    s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc, y_on_right=False)\n",
    "    \n",
    "    mpf.plot(sdf, ax = axes[0], type='candle', style = s, ylabel='')\n",
    "\n",
    "    ax_twin0 = axes[0].twinx()\n",
    "    ax_twin0.grid(False)\n",
    "    ax_twin0.yaxis.set_ticks_position('right')\n",
    "\n",
    "    ax_twin0.bar(smp['CLOCK'].to_list(), smp['Position'], color='pink', alpha=0.6, label='Position')\n",
    "    for i in range(6):\n",
    "        smp['close'] = np.zeros(smp.shape[0])\n",
    "        smp['close'].loc[smp['close_reason']==i+1] = smp['Position'].loc[smp['close_reason']==i+1] \n",
    "        ax_twin0.bar(smp['CLOCK'].to_list(), smp['close'], color=COLORS[i], alpha=0.6, label=f'Close Reason {i+1}')\n",
    "\n",
    "    ax_twin0.set_ylim(-1.0, 1.0)\n",
    "    ax_twin0.legend(loc='center right')\n",
    "\n",
    "    ## SUBPLOT 1: P_S_MA & P_L_MA & Close & Signal 1\n",
    "    axes[1].set_title('Signal 1')\n",
    "    axes[1].grid(False)\n",
    "    axes[1].yaxis.set_ticks_position('left')\n",
    "\n",
    "    smp['CLOSE'].plot(ax=axes[1], color='b')\n",
    "    smp['P_S_MA'].plot(ax=axes[1], color='orange')\n",
    "    smp['P_L_MA'].plot(ax=axes[1], color='g')\n",
    "    axes[1].legend(loc = 'upper left')\n",
    "\n",
    "    ax_twin1 = axes[1].twinx()\n",
    "    ax_twin1.grid(False)\n",
    "    ax_twin1.yaxis.set_ticks_position('right')\n",
    "\n",
    "    smp['signal1'].plot(alpha=0.5, ax = ax_twin1, color='skyblue') \n",
    "    ax_twin1.set_ylim(-1.0, 1.0)\n",
    "    ax_twin1.legend(loc='upper right')\n",
    "\n",
    "    ## SUBPLOT 2: Volume & V_L_MA & V_S_MA & Signal 2\n",
    "    axes[2].set_title('Signal 2')\n",
    "    axes[2].grid(False)\n",
    "    axes[2].yaxis.set_ticks_position('left')\n",
    "\n",
    "    axes[2].bar(smp['CLOCK'].to_list(), smp['VOLUME'], color='purple', alpha=0.3, label='Volume')\n",
    "    smp['V_S_MA'].plot(ax=axes[2], color='orange')\n",
    "    smp['V_L_MA'].plot(ax=axes[2], color='g')\n",
    "    axes[2].legend(loc = 'upper left')\n",
    "\n",
    "    ax_twin2 = axes[2].twinx()\n",
    "    ax_twin2.grid(False)\n",
    "    ax_twin2.yaxis.set_ticks_position('right')\n",
    "\n",
    "    smp['signal2'].plot(alpha=0.5, ax = ax_twin2, color='skyblue')\n",
    "    ax_twin2.set_ylim(-1.0, 1.0)\n",
    "    ax_twin2.legend(loc='upper right')\n",
    "\n",
    "    ## SUBPLOT 3: DIF & DEA & Close & Signal 3\n",
    "    axes[3].set_title('Signal 3')\n",
    "    axes[3].grid(False)\n",
    "    axes[3].yaxis.set_ticks_position('left')\n",
    "\n",
    "    smp['DIF'].plot(ax=axes[3], color='orange')\n",
    "    smp['DEA'].plot(ax=axes[3], color='g')\n",
    "    axes[3].legend(loc = 'upper left')\n",
    "\n",
    "    ax_twin3 = axes[3].twinx()\n",
    "    ax_twin3.grid(False)\n",
    "    ax_twin3.yaxis.set_ticks_position('right')\n",
    "\n",
    "    smp['signal3'].plot(alpha=0.5, ax = ax_twin3, color='skyblue')\n",
    "    ax_twin3.set_ylim(-1.0, 1.0)\n",
    "    ax_twin3.legend(loc='upper right')\n",
    "\n",
    "    ## SUBPLOT 4: Fluctuation\n",
    "    axes[4].set_title('Fluctuation')\n",
    "    axes[4].grid(False)\n",
    "    axes[4].yaxis.set_ticks_position('left')\n",
    "\n",
    "    smp['H_max'].plot(ax=axes[4], color='orange')\n",
    "    smp['CLOSE'].plot(ax=axes[4], color='b')\n",
    "    smp['L_min'].plot(ax=axes[4], color='g')\n",
    "    \n",
    "    ax_twin4 = axes[4].twinx()\n",
    "    ax_twin4.grid(False)\n",
    "    ax_twin4.yaxis.set_ticks_position('right')\n",
    "\n",
    "    smp['fluct_ts'] = FLUCT_TS\n",
    "    smp['Fluct'].plot(alpha=0.5, ax = ax_twin4, color='skyblue')\n",
    "    smp['fluct_ts'].plot(alpha=0.5, ax = ax_twin4, color = 'hotpink')\n",
    "    ax_twin4.legend(loc='upper right')\n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ssmp1 = stmp.loc[(stmp['CLOCK'] > VTD[407]) & (stmp['CLOCK'] < VTD[407]+' 15:01:00')]\n",
    "_, tmp_ssmp1 = basic_LS(tmp_ssmp1, V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all2(tmp_ssmp1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
